{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import add\n",
    "\n",
    "\n",
    "# Residual block\n",
    "def res_block_gen(model, kernal_size, filters, strides):\n",
    "    \n",
    "    gen = model\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    # Using Parametric ReLU\n",
    "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "        \n",
    "    model = add([gen, model])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def up_sampling_block(model, kernal_size, filters, strides):\n",
    "    \n",
    "    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
    "    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n",
    "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = UpSampling2D(size = 2)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_block(model, filters, kernel_size, strides):\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
    "class Generator(object):\n",
    "\n",
    "    def __init__(self, noise_shape):\n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "\n",
    "    def generator(self):\n",
    "        \n",
    "\t    gen_input = Input(shape = self.noise_shape)\n",
    "\t    \n",
    "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
    "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "\t    \n",
    "\t    gen_model = model\n",
    "        \n",
    "        # Using 16 Residual Blocks\n",
    "\t    for index in range(16):\n",
    "\t        model = res_block_gen(model, 3, 64, 1)\n",
    "\t    \n",
    "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
    "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
    "\t    model = add([gen_model, model])\n",
    "\t    \n",
    "\t    # Using 2 UpSampling Blocks\n",
    "\t    for index in range(2):\n",
    "\t        model = up_sampling_block(model, 3, 256, 1)\n",
    "\t    \n",
    "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
    "\t    model = Activation('tanh')(model)\n",
    "\t   \n",
    "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
    "        \n",
    "\t    return generator_model\n",
    "\n",
    "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
    "class Discriminator(object):\n",
    "\n",
    "    def __init__(self, image_shape):\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "    def discriminator(self):\n",
    "        \n",
    "        dis_input = Input(shape = self.image_shape)\n",
    "        \n",
    "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "        \n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        model = discriminator_block(model, 128, 3, 1)\n",
    "        model = discriminator_block(model, 128, 3, 2)\n",
    "        model = discriminator_block(model, 256, 3, 1)\n",
    "        model = discriminator_block(model, 256, 3, 2)\n",
    "        model = discriminator_block(model, 512, 3, 1)\n",
    "        model = discriminator_block(model, 512, 3, 2)\n",
    "        \n",
    "        model = Flatten()(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "       \n",
    "        model = Dense(1)(model)\n",
    "        model = Activation('sigmoid')(model) \n",
    "        \n",
    "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
    "        \n",
    "        return discriminator_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class VGG_LOSS(object):\n",
    "\n",
    "    def __init__(self, image_shape):\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    # computes VGG loss or content loss\n",
    "    def vgg_loss(self, y_true, y_pred):\n",
    "    \n",
    "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
    "        vgg19.trainable = False\n",
    "        # Make trainable as False\n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
    "        model.trainable = False\n",
    "    \n",
    "        return K.mean(K.square(model(y_true) - model(y_pred)))\n",
    "    \n",
    "def get_optimizer():\n",
    " \n",
    "    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    return adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "import tensorflow as tf\n",
    "from skimage import data, io, filters\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import randint\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
    "def SubpixelConv2D(input_shape, scale=4):\n",
    "    def subpixel_shape(input_shape):\n",
    "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
    "        output_shape = tuple(dims)\n",
    "        return output_shape\n",
    "    \n",
    "    def subpixel(x):\n",
    "        return tf.depth_to_space(x, scale)\n",
    "        \n",
    "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
    "    \n",
    "# Takes list of images and provide HR images in form of numpy array\n",
    "def hr_images(images):\n",
    "    images_hr = array(images)\n",
    "    return images_hr\n",
    "\n",
    "# Takes list of images and provide LR images in form of numpy array\n",
    "def lr_images(images_real , downscale):\n",
    "    \n",
    "    images = []\n",
    "    for img in  range(len(images_real)):\n",
    "        images.append(imresize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interp='bicubic', mode=None))\n",
    "    images_lr = array(images)\n",
    "    return images_lr\n",
    "    \n",
    "def normalize(input_data):\n",
    "\n",
    "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
    "    \n",
    "def denormalize(input_data):\n",
    "    input_data = (input_data + 1) * 127.5\n",
    "    return input_data.astype(np.uint8)\n",
    "   \n",
    " \n",
    "def load_path(path):\n",
    "    directories = []\n",
    "    if os.path.isdir(path):\n",
    "        directories.append(path)\n",
    "    for elem in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path,elem)):\n",
    "            directories = directories + load_path(os.path.join(path,elem))\n",
    "            directories.append(os.path.join(path,elem))\n",
    "    return directories\n",
    "    \n",
    "def load_data_from_dirs(dirs, ext):\n",
    "    files = []\n",
    "    file_names = []\n",
    "    count = 0\n",
    "    for d in dirs:\n",
    "        for f in os.listdir(d): \n",
    "            if f.endswith(ext):\n",
    "                image = data.imread(os.path.join(d,f))\n",
    "                if len(image.shape) > 2:\n",
    "                    files.append(image)\n",
    "                    file_names.append(os.path.join(d,f))\n",
    "                count = count + 1\n",
    "    return files     \n",
    "\n",
    "def load_data(directory, ext):\n",
    "\n",
    "    files = load_data_from_dirs(load_path(directory), ext)\n",
    "    return files\n",
    "    \n",
    "def load_training_data(directory, ext, number_of_images = 1000, train_test_ratio = 0.8):\n",
    "\n",
    "    number_of_train_images = int(number_of_images * train_test_ratio)\n",
    "    \n",
    "    files = load_data_from_dirs(load_path(directory), ext)\n",
    "    \n",
    "    if len(files) < number_of_images:\n",
    "        print(\"Number of image files are less then you specified\")\n",
    "        print(\"Please reduce number of images to %d\" % len(files))\n",
    "        sys.exit()\n",
    "        \n",
    "    test_array = array(files)\n",
    "    if len(test_array.shape) < 3:\n",
    "        print(\"Images are of not same shape\")\n",
    "        print(\"Please provide same shape images\")\n",
    "        sys.exit()\n",
    "    \n",
    "    x_train = files[:number_of_train_images]\n",
    "    x_test = files[number_of_train_images:number_of_images]\n",
    "    \n",
    "    x_train_hr = hr_images(x_train)\n",
    "    x_train_hr = normalize(x_train_hr)\n",
    "    \n",
    "    x_train_lr = lr_images(x_train, 4)\n",
    "    x_train_lr = normalize(x_train_lr)\n",
    "    \n",
    "    x_test_hr = hr_images(x_test)\n",
    "    x_test_hr = normalize(x_test_hr)\n",
    "    \n",
    "    x_test_lr = lr_images(x_test, 4)\n",
    "    x_test_lr = normalize(x_test_lr)\n",
    "    \n",
    "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
    "\n",
    "\n",
    "def load_test_data_for_model(directory, ext, number_of_images = 100):\n",
    "\n",
    "    files = load_data_from_dirs(load_path(directory), ext)\n",
    "    \n",
    "    if len(files) < number_of_images:\n",
    "        print(\"Number of image files are less then you specified\")\n",
    "        print(\"Please reduce number of images to %d\" % len(files))\n",
    "        sys.exit()\n",
    "        \n",
    "    x_test_hr = hr_images(files)\n",
    "    x_test_hr = normalize(x_test_hr)\n",
    "    \n",
    "    x_test_lr = lr_images(files, 4)\n",
    "    x_test_lr = normalize(x_test_lr)\n",
    "    \n",
    "    return x_test_lr, x_test_hr\n",
    "    \n",
    "def load_test_data(directory, ext, number_of_images = 100):\n",
    "\n",
    "    files = load_data_from_dirs(load_path(directory), ext)\n",
    "    \n",
    "    if len(files) < number_of_images:\n",
    "        print(\"Number of image files are less then you specified\")\n",
    "        print(\"Please reduce number of images to %d\" % len(files))\n",
    "        sys.exit()\n",
    "        \n",
    "    x_test_lr = lr_images(files, 4)\n",
    "    x_test_lr = normalize(x_test_lr)\n",
    "    \n",
    "    return x_test_lr\n",
    "    \n",
    "# While training save generated image(in form LR, SR, HR)\n",
    "# Save only one image as sample  \n",
    "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
    "    \n",
    "    examples = x_test_hr.shape[0]\n",
    "    print(examples)\n",
    "    value = randint(0, examples)\n",
    "    image_batch_hr = denormalize(x_test_hr)\n",
    "    image_batch_lr = x_test_lr\n",
    "    gen_img = generator.predict(image_batch_lr)\n",
    "    generated_image = denormalize(gen_img)\n",
    "    image_batch_lr = denormalize(image_batch_lr)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 1)\n",
    "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "        \n",
    "    plt.subplot(dim[0], dim[1], 2)\n",
    "    plt.imshow(generated_image[value], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 3)\n",
    "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
    "    \n",
    "    #plt.show()\n",
    "    \n",
    "# Plots and save generated images(in form LR, SR, HR) from model to test the model \n",
    "# Save output for all images given for testing  \n",
    "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
    "    \n",
    "    examples = x_test_hr.shape[0]\n",
    "    image_batch_hr = denormalize(x_test_hr)\n",
    "    image_batch_lr = x_test_lr\n",
    "    gen_img = generator.predict(image_batch_lr)\n",
    "    generated_image = denormalize(gen_img)\n",
    "    image_batch_lr = denormalize(image_batch_lr)\n",
    "    \n",
    "    for index in range(examples):\n",
    "    \n",
    "        plt.figure(figsize=figsize)\n",
    "    \n",
    "        plt.subplot(dim[0], dim[1], 1)\n",
    "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(dim[0], dim[1], 2)\n",
    "        plt.imshow(generated_image[index], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.subplot(dim[0], dim[1], 3)\n",
    "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
    "    \n",
    "        #plt.show()\n",
    "\n",
    "# Takes LR images and save respective HR images\n",
    "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
    "    \n",
    "    examples = x_test_lr.shape[0]\n",
    "    image_batch_lr = denormalize(x_test_lr)\n",
    "    gen_img = generator.predict(image_batch_lr)\n",
    "    generated_image = denormalize(gen_img)\n",
    "    \n",
    "    for index in range(examples):\n",
    "    \n",
    "        #plt.figure(figsize=figsize)\n",
    "    \n",
    "        plt.imshow(generated_image[index], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)\n",
    "    \n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "np.random.seed(10)\n",
    "# Better to use downscale factor as 4\n",
    "downscale_factor = 4\n",
    "# Remember to change image shape if you are having different size of images\n",
    "image_shape = (200,200,1)\n",
    "\n",
    "# Combined network\n",
    "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=shape)\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
    "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
    "                loss_weights=[1., 1e-3],\n",
    "                optimizer=optimizer)\n",
    "\n",
    "    return gan\n",
    "\n",
    "# default values for all parameters are given, if want defferent values you can give via commandline\n",
    "# for more info use $python train.py -h\n",
    "def train(epochs, batch_size, input_dir, output_dir, model_save_dir, number_of_images, train_test_ratio):\n",
    "    \n",
    "    x_train_lr, x_train_hr, x_test_lr, x_test_hr = Utils.load_training_data(input_dir, '.jpg', number_of_images, train_test_ratio) \n",
    "    loss = VGG_LOSS(image_shape)  \n",
    "    \n",
    "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
    "    shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
    "    \n",
    "    generator = Generator(shape).generator()\n",
    "    discriminator = Discriminator(image_shape).discriminator()\n",
    "\n",
    "    optimizer = Utils_model.get_optimizer()\n",
    "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "    \n",
    "    gan = get_gan_network(discriminator, shape, generator, optimizer, loss.vgg_loss)\n",
    "    \n",
    "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
    "    loss_file.close()\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in tqdm(range(batch_count)):\n",
    "            \n",
    "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
    "            \n",
    "            image_batch_hr = x_train_hr[rand_nums]\n",
    "            image_batch_lr = x_train_lr[rand_nums]\n",
    "            generated_images_sr = generator.predict(image_batch_lr)\n",
    "\n",
    "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
    "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "            \n",
    "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
    "            image_batch_hr = x_train_hr[rand_nums]\n",
    "            image_batch_lr = x_train_lr[rand_nums]\n",
    "\n",
    "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "            discriminator.trainable = False\n",
    "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
    "            \n",
    "            \n",
    "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
    "        print(\"gan_loss :\", gan_loss)\n",
    "        gan_loss = str(gan_loss)\n",
    "        \n",
    "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
    "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
    "        loss_file.close()\n",
    "\n",
    "        if e == 1 or e % 5 == 0:\n",
    "            Utils.plot_generated_images(output_dir, e, generator, x_test_hr, x_test_lr)\n",
    "        if e % 500 == 0:\n",
    "            generator.save(model_save_dir + 'gen_model%d.h5' % e)\n",
    "            discriminator.save(model_save_dir + 'dis_model%d.h5' % e)\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('-i', '--input_dir', action='store', dest='input_dir', default='./data/' ,\n",
    "                    help='Path for input images')\n",
    "                    \n",
    "    parser.add_argument('-o', '--output_dir', action='store', dest='output_dir', default='./output/' ,\n",
    "                    help='Path for Output images')\n",
    "    \n",
    "    parser.add_argument('-m', '--model_save_dir', action='store', dest='model_save_dir', default='./model/' ,\n",
    "                    help='Path for model')\n",
    "\n",
    "    parser.add_argument('-b', '--batch_size', action='store', dest='batch_size', default=64,\n",
    "                    help='Batch Size', type=int)\n",
    "                    \n",
    "    parser.add_argument('-e', '--epochs', action='store', dest='epochs', default=1000 ,\n",
    "                    help='number of iteratios for trainig', type=int)\n",
    "                    \n",
    "    parser.add_argument('-n', '--number_of_images', action='store', dest='number_of_images', default=1000 ,\n",
    "                    help='Number of Images', type= int)\n",
    "                    \n",
    "    parser.add_argument('-r', '--train_test_ratio', action='store', dest='train_test_ratio', default=0.8 ,\n",
    "                    help='Ratio of train and test Images', type=float)\n",
    "    \n",
    "    values = parser.parse_args()\n",
    "    \n",
    "    train(values.epochs, values.batch_size, values.input_dir, values.output_dir, values.model_save_dir, values.number_of_images, values.train_test_ratio)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
